{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Walrus outside of train.py\n",
    "\n",
    "Hello! In this demo, we'll walk you how to use the Walrus foundation model outside of our provided training code. While the training code has many features \n",
    "and options, this can also make it a bit hard to catch the essentials. That is why this notebook exists. We'll walk you through how to use\n",
    "Walrus, primarily in inference here, both with Well formatted data and if you have data you can't force into the Well's format to use our included data utilities. \n",
    "\n",
    "## Part 1: Using Walrus with Well-style datasets\n",
    "\n",
    "Prereqs:\n",
    "- Since this is using Well-style datasets, this section assumes you have Well-structured data, likely downloaded into a folder structure matching the one you'd get from downloading [The Well](https://github.com/PolymathicAI/the_well). \n",
    "- While this example only covers inference, this is using a 1.3B parameter model, so it is necessary to have either enough RAM if using CPU (slow) or VRAM if using GPU to handle a model of this size.\n",
    "\n",
    "The Walrus codebase is designed with Well-style datasets in mind. While it is not necessary to use these for Walrus,\n",
    "we're going to cover this option first since it's going to be a bit more straightforward.\n",
    "\n",
    "We're also going to take advantage of [Hydra](https://hydra.cc) to translate between OmegaConf configs and datasets and the pretrained Walrus model.\n",
    "Hydra is useful for hierarchical instantiation. It lets us break torch modules into individual component types and define models as a hierarchy \n",
    "of modular components that can be swapped out completely for other components. \n",
    "\n",
    "As a first step, we're just going to download the data. We'll just use wget to pull it from huggingface."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "checkpoint_base_path = \"./checkpoints/\"\n",
    "config_base_path = \"./configs/\"\n",
    "os.makedirs(checkpoint_base_path, exist_ok=True)\n",
    "os.makedirs(config_base_path, exist_ok=True)\n",
    "\n",
    "# # And we'll download the weights from huggingface\n",
    "# !wget  https://huggingface.co/polymathic-ai/walrus/resolve/main/extended_config.yaml \\\n",
    "#     -O {config_base_path}/extended_config.yaml\n",
    "# !wget  https://huggingface.co/polymathic-ai/walrus/resolve/main/walrus.pt \\\n",
    "#     -O {checkpoint_base_path}/walrus.pt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "%autoreload 2\n",
    "import torch\n",
    "from walrus.data.multidataset import MixedWellDataset\n",
    "from walrus.data.inflated_dataset import InflatedWellDataset\n",
    "from walrus.models import IsotropicModel\n",
    "from walrus.data.well_to_multi_transformer import ChannelsFirstWithTimeFormatter\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "from the_well.data.utils import flatten_field_names\n",
    "from walrus.trainer.normalization_strat import (\n",
    "    normalize_target,\n",
    ")\n",
    "from the_well.benchmark.metrics import make_video\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_workers: 10\n",
      "name: Walrus-wella-delta-Isotr[Space-Adapt-]-AdamW-0.0002\n",
      "automatic_setup: true\n",
      "trainer:\n",
      "  _target_: walrus.trainer.Trainer\n",
      "  max_epoch: 200\n",
      "  val_frequency: 10\n",
      "  rollout_val_frequency: 10\n",
      "  short_validation_length: 20\n",
      "  max_rollout_steps: 200\n",
      "  num_time_intervals: 5\n",
      "  enable_amp: false\n",
      "  loss_fn:\n",
      "    _target_: the_well.benchmark.metrics.MAE\n",
      "  formatter:\n",
      "    _target_: hydra.utils.get_class\n",
      "    path: walrus.data.well_to_multi_transformer.ChannelsFirstWithTimeFormatter\n",
      "  revin:\n",
      "    _target_: walrus.trainer.normalization_strat.SamplewiseRevNormalization\n",
      "    _partial_: true\n",
      "  prediction_type: delta\n",
      "  grad_acc_steps: 4\n",
      "  image_validation: true\n",
      "  video_validation: true\n",
      "  gradient_log_level: 0\n",
      "  clip_gradient: 10\n",
      "  log_interval: 200\n",
      "  loss_multiplier: 100.0\n",
      "  lr_scheduler_per_step: false\n",
      "  skip_spectral_metrics: true\n",
      "optimizer:\n",
      "  _target_: torch.optim.AdamW\n",
      "  weight_decay: 0.0001\n",
      "  eps: 1.0e-10\n",
      "  lr: 0.0002\n",
      "lr_scheduler:\n",
      "  _target_: walrus.optim.schedulers.InverseSqrtLinearWarmupSqrtCooldown\n",
      "  warmup_epochs: 10\n",
      "  cooldown_epochs: 10\n",
      "  warmup_lr_factor: 0.1\n",
      "  cooldown_lr_factor: 0.001\n",
      "model:\n",
      "  encoder:\n",
      "    _partial_: true\n",
      "    _target_: walrus.models.encoders.vstride_encoder.SpaceBagAdaptiveDVstrideEncoder\n",
      "    learned_pad: true\n",
      "    base_kernel_size1d:\n",
      "    - - 4\n",
      "      - 4\n",
      "    base_kernel_size2d:\n",
      "    - - 8\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    base_kernel_size3d:\n",
      "    - - 8\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    groups: 12\n",
      "    kernel_scales_seq:\n",
      "    - - 2\n",
      "      - 2\n",
      "    - - 4\n",
      "      - 2\n",
      "    - - 4\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    variable_downsample: true\n",
      "    variable_deterministic_ds: true\n",
      "    activation:\n",
      "      _partial_: true\n",
      "      _target_: torch.nn.SiLU\n",
      "  decoder:\n",
      "    _partial_: true\n",
      "    _target_: walrus.models.decoders.vstride_decoder.AdaptiveDVstrideDecoder\n",
      "    learned_pad: true\n",
      "    base_kernel_size1d:\n",
      "    - - 4\n",
      "      - 4\n",
      "    base_kernel_size2d:\n",
      "    - - 8\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    base_kernel_size3d:\n",
      "    - - 8\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    - - 8\n",
      "      - 4\n",
      "    groups: 12\n",
      "    activation:\n",
      "      _partial_: true\n",
      "      _target_: torch.nn.SiLU\n",
      "  processor:\n",
      "    space_mixing:\n",
      "      _partial_: true\n",
      "      _target_: walrus.models.spatial_blocks.full_attention.FullAttention\n",
      "      num_heads: 16\n",
      "      mlp_dim: null\n",
      "    time_mixing:\n",
      "      _partial_: true\n",
      "      _target_: walrus.models.temporal_blocks.axial_time_attention.AxialTimeAttention\n",
      "      num_heads: 16\n",
      "      bias_type: rel\n",
      "    channel_mixing:\n",
      "      _partial_: true\n",
      "      _target_: torch.nn.Identity\n",
      "    _partial_: true\n",
      "    _target_: walrus.models.spatiotemporal_blocks.space_time_split.SpaceTimeSplitBlock\n",
      "  norm_layer:\n",
      "    _partial_: true\n",
      "    _target_: walrus.models.shared_utils.normalization.RMSGroupNorm\n",
      "  _target_: walrus.models.IsotropicModel\n",
      "  hidden_dim: 1408\n",
      "  projection_dim: 48\n",
      "  intermediate_dim: 352\n",
      "  processor_blocks: 40\n",
      "  drop_path: 0.05\n",
      "  groups: 16\n",
      "  max_d: 3\n",
      "  static_axes: true\n",
      "  weight_tied_axes: false\n",
      "  causal_in_time: true\n",
      "  include_d:\n",
      "  - 2\n",
      "  - 3\n",
      "  override_dimensionality: 0\n",
      "  jitter_patches: true\n",
      "  gradient_checkpointing_freq: 2\n",
      "  use_periodic_fixed_jitter: true\n",
      "  input_field_drop: 0.0\n",
      "data:\n",
      "  field_index_map_override:\n",
      "    closed_boundary: 0\n",
      "    open_boundary: 1\n",
      "    bias_correction: 2\n",
      "    pressure: 3\n",
      "    velocity_x: 4\n",
      "    velocity_y: 5\n",
      "    velocity_z: 6\n",
      "    zeros_like_density: 7\n",
      "    speed_of_sound: 8\n",
      "    concentration: 9\n",
      "    D_xx: 10\n",
      "    D_xy: 11\n",
      "    D_xz: 12\n",
      "    D_yx: 13\n",
      "    D_yy: 14\n",
      "    D_yz: 15\n",
      "    D_zx: 16\n",
      "    D_zy: 17\n",
      "    D_zz: 18\n",
      "    E_xx: 19\n",
      "    E_xy: 20\n",
      "    E_xz: 21\n",
      "    E_yx: 22\n",
      "    E_yy: 23\n",
      "    E_yz: 24\n",
      "    E_zx: 25\n",
      "    E_zy: 26\n",
      "    E_zz: 27\n",
      "    density: 28\n",
      "    energy: 29\n",
      "    velocity_r: 30\n",
      "    velocity_theta: 31\n",
      "    velocity_phi: 32\n",
      "    momentum_x: 33\n",
      "    momentum_y: 34\n",
      "    momentum_z: 35\n",
      "    pressure_re: 36\n",
      "    pressure_im: 37\n",
      "    mask: 38\n",
      "    magnetic_field_x: 39\n",
      "    magnetic_field_y: 40\n",
      "    magnetic_field_z: 41\n",
      "    A: 42\n",
      "    B: 43\n",
      "    height: 44\n",
      "    internal_energy: 45\n",
      "    temperature: 46\n",
      "    electron_fraction: 47\n",
      "    entropy: 48\n",
      "    magnetic_field_log_r: 49\n",
      "    magnetic_field_theta: 50\n",
      "    magnetic_field_phi: 51\n",
      "    velocity_log_r: 52\n",
      "    buoyancy: 53\n",
      "    tracer: 54\n",
      "    log10_density: 55\n",
      "    log10_temperature: 56\n",
      "    c_zz: 57\n",
      "    C_xx: 58\n",
      "    C_xy: 59\n",
      "    C_xz: 60\n",
      "    C_yx: 61\n",
      "    C_yy: 62\n",
      "    C_yz: 63\n",
      "    C_zx: 64\n",
      "    C_zy: 65\n",
      "    C_zz: 66\n",
      "  transform:\n",
      "    train:\n",
      "      _target_: the_well.data.augmentation.RandomRotation90\n",
      "      p: 1.0\n",
      "  well_base_path: /rds/general/user/ss2524/home/walrus/datasets/datasets/\n",
      "  wandb_data_name: well_allmain_only\n",
      "  module_parameters:\n",
      "    _target_: walrus.data.MixedWellDataModule\n",
      "    batch_size: 2\n",
      "    n_steps_input: 6\n",
      "    n_steps_output: 1\n",
      "    min_dt_stride: 1\n",
      "    max_dt_stride: 5\n",
      "    max_samples: 2000\n",
      "    well_dataset_info:\n",
      "      active_matter: null\n",
      "      shear_flow:\n",
      "        include_filters: []\n",
      "        exclude_filters: []\n",
      "auto_resume: true\n",
      "folder_override: ''\n",
      "checkpoint_override: ''\n",
      "config_override: null\n",
      "validation_mode: false\n",
      "frozen_components:\n",
      "- model\n",
      "distribution:\n",
      "  distribution_type: hsdp\n",
      "  local_size: 4\n",
      "logger:\n",
      "  wandb: true\n",
      "  wandb_project_name: walrus_Training_Attempts\n",
      "checkpoint:\n",
      "  _target_: walrus.trainer.checkpoints.CheckPointer\n",
      "  save_dir: /mnt/home/polymathic/ceph/walrus_logging/runs/Walrus_ft_major_v2-wella-delta-Isotr[Space-Adapt-]-AdamW-0.0002/0/checkpoints\n",
      "  load_checkpoint_path: null\n",
      "  coalesced_checkpoint_path: null\n",
      "  save_best: true\n",
      "  checkpoint_frequency: 20\n",
      "  align_fields: true\n",
      "  load_chkpt_after_finetuning_expansion: false\n",
      "finetuning_mods: {}\n",
      "experiment_dir: /mnt/home/polymathic/ceph/walrus_logging/runs\n",
      "\n"
     ]
    }
   ],
   "source": [
    "%autoreload 2\n",
    "import torch\n",
    "from walrus.data.multidataset import MixedWellDataset\n",
    "from walrus.data.inflated_dataset import InflatedWellDataset\n",
    "from walrus.models import IsotropicModel\n",
    "from walrus.data.well_to_multi_transformer import ChannelsFirstWithTimeFormatter\n",
    "from hydra.utils import instantiate\n",
    "from omegaconf import DictConfig, OmegaConf, open_dict\n",
    "from the_well.data.utils import flatten_field_names\n",
    "from walrus.trainer.normalization_strat import (\n",
    "    normalize_target,\n",
    ")\n",
    "from the_well.benchmark.metrics import make_video\n",
    "\n",
    "checkpoint_path = f\"{checkpoint_base_path}/walrus.pt\"\n",
    "checkpoint_config_path = f\"{config_base_path}/extended_config.yaml\"\n",
    "checkpoint = torch.load(checkpoint_path, map_location=\"cpu\", weights_only=True)[\"app\"][\"model\"]\n",
    "config = OmegaConf.load(checkpoint_config_path)\n",
    "\n",
    "# Lets start by examining our config file\n",
    "\n",
    "print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# checkpoint_config_path = f\"{config_base_path}/extended_config.yaml\"\n",
    "# config = OmegaConf.load(checkpoint_config_path)\n",
    "\n",
    "# # Lets start by examining our config file\n",
    "\n",
    "# print(OmegaConf.to_yaml(config))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are a couple key configuration areas since we're using Walrus outside of the training code:\n",
    "- **config.data** - Defines the input data configuration used during training this checkpoint. \n",
    "    - **config.data.field_index_map_override** - Gives a mapping between physical fields and indices keys in the embedding layer.  \n",
    "- **config.model** - Defines the structure of the Walrus model itself. \n",
    "- **config.trainer.revin** - Tells us what normalization approach to use.\n",
    "- **config.trainer.formatter** - Tells us what to use to format the data before feeding it into the model. \n",
    "\n",
    "We'll start off this process by initializing the data and model. The data size helps us determine the size of the input embedding layer. For ease of use, we'll\n",
    "load the full `DataModule` object which has a bit higher overhead compared to loading just the required dataset, but will make the overall process easier.\n",
    "\n",
    "Since we're using a pretrained checkpoint, we do not need the datamodule to prefetch field information from the data. Instead, we'll be using the \n",
    "saved information already in the data config. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'field_index_map_override': {'closed_boundary': 0, 'open_boundary': 1, 'bias_correction': 2, 'pressure': 3, 'velocity_x': 4, 'velocity_y': 5, 'velocity_z': 6, 'zeros_like_density': 7, 'speed_of_sound': 8, 'concentration': 9, 'D_xx': 10, 'D_xy': 11, 'D_xz': 12, 'D_yx': 13, 'D_yy': 14, 'D_yz': 15, 'D_zx': 16, 'D_zy': 17, 'D_zz': 18, 'E_xx': 19, 'E_xy': 20, 'E_xz': 21, 'E_yx': 22, 'E_yy': 23, 'E_yz': 24, 'E_zx': 25, 'E_zy': 26, 'E_zz': 27, 'density': 28, 'energy': 29, 'velocity_r': 30, 'velocity_theta': 31, 'velocity_phi': 32, 'momentum_x': 33, 'momentum_y': 34, 'momentum_z': 35, 'pressure_re': 36, 'pressure_im': 37, 'mask': 38, 'magnetic_field_x': 39, 'magnetic_field_y': 40, 'magnetic_field_z': 41, 'A': 42, 'B': 43, 'height': 44, 'internal_energy': 45, 'temperature': 46, 'electron_fraction': 47, 'entropy': 48, 'magnetic_field_log_r': 49, 'magnetic_field_theta': 50, 'magnetic_field_phi': 51, 'velocity_log_r': 52, 'buoyancy': 53, 'tracer': 54, 'log10_density': 55, 'log10_temperature': 56, 'c_zz': 57, 'C_xx': 58, 'C_xy': 59, 'C_xz': 60, 'C_yx': 61, 'C_yy': 62, 'C_yz': 63, 'C_zx': 64, 'C_zy': 65, 'C_zz': 66}, 'transform': {'train': {'_target_': 'the_well.data.augmentation.RandomRotation90', 'p': 1.0}}, 'well_base_path': '/rds/general/user/ss2524/home/walrus/datasets/datasets/', 'wandb_data_name': 'well_allmain_only', 'module_parameters': {'_target_': 'walrus.data.MixedWellDataModule', 'batch_size': 2, 'n_steps_input': 6, 'n_steps_output': 1, 'min_dt_stride': 1, 'max_dt_stride': 5, 'max_samples': 2000, 'well_dataset_info': {'active_matter': None, 'shear_flow': {'include_filters': [], 'exclude_filters': []}}}}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# config.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "well_base_path = \"/rds/general/user/ss2524/home/walrus/datasets/datasets/\"\n",
    "\n",
    "# First we're going to remove non-Well data since that uses absolute paths which are likely not on your system\n",
    "# with open_dict(config):\n",
    "#     del(config.data.module_parameters.well_dataset_info.flowbench_FPO_NS_2D_512x128_harmonics)\n",
    "\n",
    "# The dataset objects precompute a number of dataset stats on init, so this may take a little while\n",
    "data_module = instantiate(config.data.module_parameters, \n",
    "                          well_base_path=well_base_path,\n",
    "                          world_size=1,\n",
    "                          rank=0,\n",
    "                          data_workers=1, \n",
    "                          field_index_map_override=config.data.get(\"field_index_map_override\", {}), # Use the previous field maps to avoid cycling through the data\n",
    "                          prefetch_field_names=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "From here, we want to use the `field_to_index_map` object to determine the dimension of the encoder. Since we're\n",
    "just using the Well data in this example, this shouldn't change from the pre-existing map, but we'll get it from the dataset\n",
    "as an example. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ss2524/home/walrus/walrus/models/temporal_blocks/axial_time_attention.py:38: FutureWarning: `nn.init.kaiming_uniform` is now deprecated in favor of `nn.init.kaiming_uniform_`.\n",
      "  init.kaiming_uniform(\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "IsotropicModel(\n",
       "  (patch_jitterer): FixedPatchJittererBoundaryPad()\n",
       "  (embed): ModuleDict(\n",
       "    (2): SpaceBagAdaptiveDVstrideEncoder(\n",
       "      (proj1): Conv3d(67, 352, kernel_size=(8, 8, 8), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): RMSGroupNorm(16, 352, eps=1e-06, affine=True)\n",
       "      (act): SiLU()\n",
       "      (proj2): Conv3d(352, 1408, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "      (norm2): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "    )\n",
       "    (3): SpaceBagAdaptiveDVstrideEncoder(\n",
       "      (proj1): Conv3d(67, 352, kernel_size=(8, 8, 8), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): RMSGroupNorm(16, 352, eps=1e-06, affine=True)\n",
       "      (act): SiLU()\n",
       "      (proj2): Conv3d(352, 1408, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "      (norm2): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "    )\n",
       "  )\n",
       "  (blocks): ModuleList(\n",
       "    (0): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): Identity()\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (1): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.001)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.001)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (2): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.003)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.003)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (3): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.004)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.004)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (4): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.005)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.005)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (5): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.006)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.006)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (6): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.008)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.008)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (7): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.009)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.009)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (8): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.010)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.010)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (9): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.012)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.012)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (10): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.013)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.013)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (11): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.014)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (12): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.015)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.015)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (13): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.017)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.017)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (14): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.018)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.018)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (15): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.019)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.019)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (16): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.021)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.021)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (17): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.022)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.022)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (18): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.023)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.023)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (19): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.024)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.024)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (20): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.026)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.026)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (21): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.027)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.027)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (22): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.028)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.028)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (23): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.029)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (24): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.031)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.031)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (25): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.032)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.032)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (26): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.033)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.033)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (27): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.035)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.035)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (28): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.036)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.036)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (29): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.037)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.037)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (30): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.038)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.038)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (31): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.040)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.040)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (32): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.041)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.041)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (33): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.042)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.042)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (34): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.044)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.044)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (35): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.045)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.045)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (36): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.046)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.046)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (37): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.047)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.047)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (38): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.049)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.049)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "    (39): SpaceTimeSplitBlock(\n",
       "      (space_mixing): FullAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (fused_ff_qkv): Linear(in_features=1408, out_features=9856, bias=True)\n",
       "        (activation): SwiGLU()\n",
       "        (ff_out): Linear(in_features=2816, out_features=1408, bias=True)\n",
       "        (attn_out): Linear(in_features=1408, out_features=1408, bias=False)\n",
       "        (q_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (k_norm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rotary_emb): RotaryEmbedding()\n",
       "        (drop_path): DropPath(drop_prob=0.050)\n",
       "      )\n",
       "      (time_mixing): AxialTimeAttention(\n",
       "        (norm1): RMSGroupNorm(16, 1408, eps=1e-06, affine=True)\n",
       "        (input_head): Conv3d(1408, 4224, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (output_head): Conv3d(1408, 1408, kernel_size=(1, 1, 1), stride=(1, 1, 1))\n",
       "        (qnorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (knorm): LayerNorm((88,), eps=1e-05, elementwise_affine=True)\n",
       "        (rel_pos_bias): RelativePositionBias(\n",
       "          (relative_attention_bias): Embedding(32, 16)\n",
       "        )\n",
       "        (drop_path): DropPath(drop_prob=0.050)\n",
       "      )\n",
       "      (channel_mixing): Identity()\n",
       "    )\n",
       "  )\n",
       "  (debed): ModuleDict(\n",
       "    (2): AdaptiveDVstrideDecoder(\n",
       "      (proj1): ConvTranspose3d(1408, 352, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): RMSGroupNorm(16, 352, eps=1e-06, affine=True)\n",
       "      (act): SiLU()\n",
       "      (proj2): ConvTranspose3d(352, 67, kernel_size=(8, 8, 8), stride=(1, 1, 1))\n",
       "    )\n",
       "    (3): AdaptiveDVstrideDecoder(\n",
       "      (proj1): ConvTranspose3d(1408, 352, kernel_size=(4, 4, 4), stride=(1, 1, 1), bias=False)\n",
       "      (norm1): RMSGroupNorm(16, 352, eps=1e-06, affine=True)\n",
       "      (act): SiLU()\n",
       "      (proj2): ConvTranspose3d(352, 67, kernel_size=(8, 8, 8), stride=(1, 1, 1))\n",
       "    )\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_to_index_map = data_module.train_dataset.field_to_index_map\n",
    "# Retrieve the number of fields used in training\n",
    "# from the mapping of field to index and incrementing by 1\n",
    "total_input_fields = max(field_to_index_map.values()) + 1\n",
    "\n",
    "model: torch.nn.Module = instantiate(\n",
    "    config.model,\n",
    "    n_states=total_input_fields,\n",
    ")\n",
    "model.load_state_dict(checkpoint)\n",
    "\n",
    "# Move to the device we want\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have a pretrained model, let's look at how we would use it. First, we need a couple helper objects - the formatter and the normalization object. Since Walrus was trained with reversible normalization, it can be easier to implement outside of the data loader.\n",
    "\n",
    "The formatter object converts data from the Well convention format to the format ingested by Walrus. \n",
    "\n",
    "The normalization object normalizes the data before it enters the model and denormalizes the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "formatter = ChannelsFirstWithTimeFormatter()\n",
    "revin = instantiate(config.trainer.revin)() # This is a functools partial by default"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Before we use the model, let's look at the structure of the data. This will give us important information for how we can use the model when we don't have Well-formatted data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Metadata: WellMetadata(dataset_name='shear_flow', n_spatial_dims=3, spatial_resolution=(256, 512, 1), scalar_names=[], constant_scalar_names=['Reynolds', 'Schmidt'], field_names={0: ['tracer', 'pressure'], 1: ['velocity_x', 'velocity_y', 'velocity_z'], 2: []}, constant_field_names={0: [], 1: [], 2: []}, boundary_condition_types=['PERIODIC', 'PERIODIC'], n_files=28, n_trajectories_per_file=[4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4, 4], n_steps_per_trajectory=[200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200, 200], grid_type='cartesian')\n",
      "Trajectory example keys: dict_keys(['input_fields', 'output_fields', 'constant_scalars', 'boundary_conditions', 'space_grid', 'input_time_grid', 'output_time_grid', 'padded_field_mask', 'field_indices', 'metadata'])\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Grab one trajectory to use as an example\n",
    "dataset_index = 0 # Corresponds to [--acoustic_scatter_inclusions--] shear_Flow?\n",
    "dataset = data_module.rollout_val_datasets[dataset_index].sub_dsets[0]\n",
    "metadata = dataset.metadata\n",
    "\n",
    "trajectory_example = next(iter(data_module.rollout_val_dataloaders()[dataset_index]))\n",
    "\n",
    "print(\"Metadata:\", metadata)\n",
    "print(\"Trajectory example keys:\", trajectory_example.keys())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<walrus.data.multidataset.MixedWellDataset at 0x147afc81ac80>]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data_module.rollout_val_datasets"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The `MixedWellDataset` object outputs several important fields:\n",
    "- `input_fields` - These are time varying state variables to use as input. \n",
    "- `out_fields` - Time varying state variables that the model is expected to predict.\n",
    "- `constant_fields` - Input values that don't vary with time. \n",
    "- `boundary_conditions` - list of lists containing the properties of the borders. These are restricted to topological details \"periodic\", \"open\", and \"wall\"/closed. For instance, the values [[0, 0], [1, 0], [2, 2]] would indicate the first axis (x) has closed boundaries on both sides, while the second (y) has an open boundary at ($y=0$) and closed at ($y=1$). The third (z) is periodic.\n",
    "- `padded_field_mask` - When applying rotations, it can be difficult to tell which tensor-valued fields are real and which are from padding into higher dimensions. This lets us know which are which so we can evaluate only the true fields.\n",
    "- `field_indices` - This is a new object in Walrus's `MixedWellDataset` that tracks mappings from field names to indices. This tells the model what types of fields it's using at any given time. \n",
    "- `metadata` - This is a typical Well metadata object, but as this type of object can sample from multiple data sources, this is passed to make it easier to track what type of data we're working with. \n",
    "\n",
    "```\n",
    "# Boundary condition codes\n",
    "class BoundaryCondition(Enum):\n",
    "    WALL = 0\n",
    "    OPEN = 1\n",
    "    PERIODIC = 2\n",
    "```\n",
    "\n",
    "Now lets see how we can use the model to forecast the evolution of this field! Let's define a helper function which performs an autoregressive rollout. \n",
    "\n",
    "We want this helper to:\n",
    "- Move our data to the target device\n",
    "- Reshape the data into the format expected by Walrus\n",
    "- Rollout the model as many steps as we have reference data for, performing appropriate normalization as we go"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "from walrus.trainer.training import expand_mask_to_match\n",
    "\n",
    "def rollout_model(model, revin, batch, formatter, max_rollout_steps=200, model_epsilon=1e-5, device=torch.device(\"cpu\")):\n",
    "    \"\"\"Rollout the model for as many steps as we have data for.\n",
    "\n",
    "    Simplified version of the trainer method for demo purposes.\n",
    "    \"\"\"\n",
    "    metadata = batch[\"metadata\"]\n",
    "    batch = {\n",
    "        k: v.to(device)\n",
    "        if k not in {\"metadata\", \"boundary_conditions\"}\n",
    "        else v\n",
    "        for k, v in batch.items()\n",
    "    }\n",
    "    # Extract mask and move to device for loss eval\n",
    "    if (\n",
    "        \"mask\" in batch[\"metadata\"].constant_field_names[0] # Assuming all metadata in batch are the same\n",
    "    ):\n",
    "        mask_index = batch[\"metadata\"].constant_field_names[0].index(\"mask\")\n",
    "        mask = batch[\"constant_fields\"][..., mask_index : mask_index + 1]\n",
    "        mask = mask.to(device, dtype=torch.bool)\n",
    "    else:\n",
    "        mask = None\n",
    "\n",
    "    inputs, y_ref = formatter.process_input(\n",
    "        batch,\n",
    "        causal_in_time=model.causal_in_time,\n",
    "        predict_delta=True,\n",
    "        train=False,\n",
    "    )\n",
    "\n",
    "    # Inputs T B C H [W D], y_ref B T H [W D] C\n",
    "    T_in = batch[\"input_fields\"].shape[1]\n",
    "    max_rollout_steps = max_rollout_steps + (T_in - 1)\n",
    "    rollout_steps = min(y_ref.shape[1], max_rollout_steps)  # Number of timesteps in target\n",
    "    train_rollout_limit = 1\n",
    "\n",
    "    y_ref = y_ref[:, :rollout_steps] # If we set a maximum number of rollout steps, just cut it off now to save memory\n",
    "    # Create a moving batch of one step at a time\n",
    "    moving_batch = copy.deepcopy(batch)\n",
    "    y_preds = []\n",
    "    # Rollout the model - Causal in time gets more predictions from the first step\n",
    "    for i in range(train_rollout_limit - 1, rollout_steps):\n",
    "        # Don't fill causal_in_time here since that only affects y_ref\n",
    "        inputs, _ = formatter.process_input(moving_batch)\n",
    "        inputs = list(inputs)\n",
    "        with torch.no_grad():\n",
    "            normalization_stats = revin.compute_stats(\n",
    "                inputs[0], metadata, epsilon=model_epsilon\n",
    "            )\n",
    "        # NOTE - Currently assuming only [0] (fields) needs normalization\n",
    "        normalized_inputs = inputs[:]  # Shallow copy\n",
    "        normalized_inputs[0] = revin.normalize_stdmean(\n",
    "            normalized_inputs[0], normalization_stats\n",
    "        )\n",
    "        y_pred = model(\n",
    "            normalized_inputs[0],\n",
    "            normalized_inputs[1],\n",
    "            normalized_inputs[2].tolist(),\n",
    "            metadata=metadata,\n",
    "        )\n",
    "        # During validation, don't maintain full inner predictions\n",
    "        if model.causal_in_time:\n",
    "            y_pred = y_pred[-1:]  # y_pred is T first, y_ref is not\n",
    "        # In validation, we want to reconstruct predictions on original scale\n",
    "        y_pred = (inputs[0][-y_pred.shape[0]:].float() \n",
    "                  + revin.denormalize_delta(y_pred, normalization_stats))  # Unnormalize delta and add to input\n",
    "        y_pred = formatter.process_output(y_pred, metadata)[..., : y_ref.shape[-1]]  # Cut off constant channels\n",
    "\n",
    "        # If we have masked fields, just move them back to zeros\n",
    "        if mask is not None:\n",
    "            mask_pred = expand_mask_to_match(mask, y_pred)\n",
    "            y_pred.masked_fill_(mask_pred, 0)\n",
    "\n",
    "        y_pred = y_pred.masked_fill(~batch[\"padded_field_mask\"], 0.0)\n",
    "\n",
    "        # If not last step, update moving batch for autoregressive prediction\n",
    "        if i != rollout_steps - 1:\n",
    "            moving_batch[\"input_fields\"] = torch.cat(\n",
    "                [moving_batch[\"input_fields\"][:, 1:], y_pred[:, -1:]], dim=1\n",
    "            )\n",
    "        # For causal models, we get use full predictions for the first batch and\n",
    "        # incremental predictions for subsequent batches - concat 1:T to y_ref for loss eval\n",
    "        if model.causal_in_time and i == train_rollout_limit - 1:\n",
    "            y_preds.append(y_pred)\n",
    "        else:\n",
    "            y_preds.append(y_pred[:, -1:])\n",
    "    y_pred_out = torch.cat(y_preds, dim=1)\n",
    "    if mask is not None:\n",
    "        mask_ref = expand_mask_to_match(mask, y_ref)\n",
    "        y_ref.masked_fill_(mask_ref, 0)\n",
    "    return y_pred_out, y_ref"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets make our forecast!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    trajectory_example[\"padded_field_mask\"] = trajectory_example[\"padded_field_mask\"].to(device) # We're going to want this out here too\n",
    "    inputs, y_ref = formatter.process_input(\n",
    "        trajectory_example,\n",
    "        causal_in_time=model.causal_in_time,\n",
    "        predict_delta=True,\n",
    "        train=False,\n",
    "    )\n",
    "    y_pred, y_ref = rollout_model(\n",
    "        model,\n",
    "        revin,\n",
    "        trajectory_example,\n",
    "        formatter,\n",
    "        max_rollout_steps=200,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Lets get some extra info so we can visualize our data effectively\n",
    "    # Remove unused fields\n",
    "    y_pred, y_ref = (\n",
    "        y_pred[..., trajectory_example[\"padded_field_mask\"]],\n",
    "        y_ref[..., trajectory_example[\"padded_field_mask\"]],\n",
    "    )\n",
    "    # Collecting names to make detailed output logs\n",
    "    field_names = flatten_field_names(metadata, include_constants=False)\n",
    "    used_field_names = [\n",
    "        f\n",
    "        for i, f in enumerate(field_names)\n",
    "        if trajectory_example[\"padded_field_mask\"][i]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'ffmpeg'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[24], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mthe_well\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbenchmark\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m make_video\n\u001b[1;32m      2\u001b[0m output_dir \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m./figures/\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m----> 4\u001b[0m \u001b[43mmake_video\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_pred\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# First sample only in batch\u001b[39;49;00m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_ref\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# First sample only in batch\u001b[39;49;00m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetadata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m    \u001b[49m\u001b[43moutput_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43moutput_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      9\u001b[0m \u001b[43m    \u001b[49m\u001b[43mepoch_number\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mshear_flow_example\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Misleading parameter name, but duck typing lets it be used for naming the output. Needs upstream fix.\u001b[39;49;00m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfield_name_overrides\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mused_field_names\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Fields actually used\u001b[39;49;00m\n\u001b[1;32m     11\u001b[0m \u001b[43m    \u001b[49m\u001b[43msize_multiplier\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m1.\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# \u001b[39;49;00m\n\u001b[1;32m     12\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/site-packages/the_well/benchmark/metrics/plottable_data.py:438\u001b[0m, in \u001b[0;36mmake_video\u001b[0;34m(predicted_images, true_images, metadata, output_dir, epoch_number, field_name_overrides, size_multiplier)\u001b[0m\n\u001b[1;32m    435\u001b[0m \u001b[38;5;66;03m# Render frames efficiently using FFMpeg writer\u001b[39;00m\n\u001b[1;32m    436\u001b[0m data_arrays \u001b[38;5;241m=\u001b[39m [true_images, predicted_images, error_images]\n\u001b[0;32m--> 438\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Writer\u001b[38;5;241m.\u001b[39msaving(fig, output_file, dpi):\n\u001b[1;32m    439\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m frame_idx \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(n_frames):\n\u001b[1;32m    440\u001b[0m         \u001b[38;5;66;03m# Update all images\u001b[39;00m\n\u001b[1;32m    441\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m im, row, col \u001b[38;5;129;01min\u001b[39;00m ims:\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/contextlib.py:135\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__enter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    133\u001b[0m \u001b[38;5;28;01mdel\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39margs, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mkwds, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfunc\n\u001b[1;32m    134\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 135\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    136\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m:\n\u001b[1;32m    137\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mgenerator didn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mt yield\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/site-packages/matplotlib/animation.py:221\u001b[0m, in \u001b[0;36mAbstractMovieWriter.saving\u001b[0;34m(self, fig, outfile, dpi, *args, **kwargs)\u001b[0m\n\u001b[1;32m    216\u001b[0m     _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mDisabling savefig.bbox = \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtight\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m, as it may cause \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    217\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mframe size to vary, which is inappropriate for \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    218\u001b[0m               \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124manimation.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    220\u001b[0m \u001b[38;5;66;03m# This particular sequence is what contextlib.contextmanager wants\u001b[39;00m\n\u001b[0;32m--> 221\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msetup\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moutfile\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdpi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    222\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m mpl\u001b[38;5;241m.\u001b[39mrc_context({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124msavefig.bbox\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28;01mNone\u001b[39;00m}):\n\u001b[1;32m    223\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/site-packages/matplotlib/animation.py:312\u001b[0m, in \u001b[0;36mMovieWriter.setup\u001b[0;34m(self, fig, outfile, dpi)\u001b[0m\n\u001b[1;32m    309\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_w, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_h \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_adjust_frame_size()\n\u001b[1;32m    310\u001b[0m \u001b[38;5;66;03m# Run here so that grab_frame() can write the data to a pipe. This\u001b[39;00m\n\u001b[1;32m    311\u001b[0m \u001b[38;5;66;03m# eliminates the need for temp files.\u001b[39;00m\n\u001b[0;32m--> 312\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_run\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/site-packages/matplotlib/animation.py:322\u001b[0m, in \u001b[0;36mMovieWriter._run\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    319\u001b[0m _log\u001b[38;5;241m.\u001b[39minfo(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mMovieWriter._run: running command: \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m    320\u001b[0m           cbook\u001b[38;5;241m.\u001b[39m_pformat_subprocess(command))\n\u001b[1;32m    321\u001b[0m PIPE \u001b[38;5;241m=\u001b[39m subprocess\u001b[38;5;241m.\u001b[39mPIPE\n\u001b[0;32m--> 322\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_proc \u001b[38;5;241m=\u001b[39m \u001b[43msubprocess\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mPopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    323\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcommand\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdin\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstdout\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstderr\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mPIPE\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    324\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubprocess_creation_flags\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/subprocess.py:971\u001b[0m, in \u001b[0;36mPopen.__init__\u001b[0;34m(self, args, bufsize, executable, stdin, stdout, stderr, preexec_fn, close_fds, shell, cwd, env, universal_newlines, startupinfo, creationflags, restore_signals, start_new_session, pass_fds, user, group, extra_groups, encoding, errors, text, umask, pipesize)\u001b[0m\n\u001b[1;32m    967\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtext_mode:\n\u001b[1;32m    968\u001b[0m             \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr \u001b[38;5;241m=\u001b[39m io\u001b[38;5;241m.\u001b[39mTextIOWrapper(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr,\n\u001b[1;32m    969\u001b[0m                     encoding\u001b[38;5;241m=\u001b[39mencoding, errors\u001b[38;5;241m=\u001b[39merrors)\n\u001b[0;32m--> 971\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_execute_child\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mexecutable\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpreexec_fn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclose_fds\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    972\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mpass_fds\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcwd\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43menv\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    973\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstartupinfo\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreationflags\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mshell\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    974\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mp2cread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mp2cwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    975\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mc2pread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mc2pwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    976\u001b[0m \u001b[43m                        \u001b[49m\u001b[43merrread\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merrwrite\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    977\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mrestore_signals\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    978\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mgid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgids\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43muid\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mumask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    979\u001b[0m \u001b[43m                        \u001b[49m\u001b[43mstart_new_session\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    980\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m:\n\u001b[1;32m    981\u001b[0m     \u001b[38;5;66;03m# Cleanup if the child failed starting.\u001b[39;00m\n\u001b[1;32m    982\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m f \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mfilter\u001b[39m(\u001b[38;5;28;01mNone\u001b[39;00m, (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdin, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstdout, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstderr)):\n",
      "File \u001b[0;32m~/anaconda3/envs/interp/lib/python3.10/subprocess.py:1863\u001b[0m, in \u001b[0;36mPopen._execute_child\u001b[0;34m(self, args, executable, preexec_fn, close_fds, pass_fds, cwd, env, startupinfo, creationflags, shell, p2cread, p2cwrite, c2pread, c2pwrite, errread, errwrite, restore_signals, gid, gids, uid, umask, start_new_session)\u001b[0m\n\u001b[1;32m   1861\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m errno_num \u001b[38;5;241m!=\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[1;32m   1862\u001b[0m         err_msg \u001b[38;5;241m=\u001b[39m os\u001b[38;5;241m.\u001b[39mstrerror(errno_num)\n\u001b[0;32m-> 1863\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(errno_num, err_msg, err_filename)\n\u001b[1;32m   1864\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m child_exception_type(err_msg)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'ffmpeg'"
     ]
    }
   ],
   "source": [
    "from the_well.benchmark.metrics import make_video\n",
    "output_dir = \"./figures/\"\n",
    "\n",
    "make_video(\n",
    "    y_pred[0],  # First sample only in batch\n",
    "    y_ref[0],  # First sample only in batch\n",
    "    metadata,\n",
    "    output_dir=output_dir,\n",
    "    epoch_number=\"shear_flow_example\",  # Misleading parameter name, but duck typing lets it be used for naming the output. Needs upstream fix.\n",
    "    field_name_overrides=used_field_names,  # Fields actually used\n",
    "    size_multiplier=1.,  # \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[[[ 5.0002e-01,  6.1847e-05,  5.0691e-01, -1.2522e-04]],\n",
       "\n",
       "          [[ 4.9993e-01,  5.0736e-05,  5.0693e-01, -3.3255e-04]],\n",
       "\n",
       "          [[ 4.9991e-01,  5.8552e-05,  5.0691e-01, -5.5628e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0001e-01,  4.3115e-05,  5.0695e-01,  6.1874e-04]],\n",
       "\n",
       "          [[ 5.0004e-01,  6.1625e-05,  5.0693e-01,  4.0768e-04]],\n",
       "\n",
       "          [[ 5.0003e-01,  7.6169e-05,  5.0689e-01,  1.5615e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0007e-01, -1.3092e-04,  5.0712e-01, -8.7204e-05]],\n",
       "\n",
       "          [[ 5.0001e-01, -1.3817e-04,  5.0712e-01, -3.1444e-04]],\n",
       "\n",
       "          [[ 4.9996e-01, -1.1764e-04,  5.0712e-01, -5.5506e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0002e-01, -1.4480e-04,  5.0714e-01,  6.0072e-04]],\n",
       "\n",
       "          [[ 5.0006e-01, -1.2966e-04,  5.0712e-01,  4.2091e-04]],\n",
       "\n",
       "          [[ 5.0007e-01, -1.1743e-04,  5.0710e-01,  1.9222e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0010e-01, -3.2149e-04,  5.0733e-01, -5.1899e-05]],\n",
       "\n",
       "          [[ 5.0006e-01, -3.2724e-04,  5.0734e-01, -2.6747e-04]],\n",
       "\n",
       "          [[ 4.9996e-01, -3.1228e-04,  5.0735e-01, -5.0832e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0004e-01, -3.2819e-04,  5.0734e-01,  5.7080e-04]],\n",
       "\n",
       "          [[ 5.0006e-01, -3.2252e-04,  5.0733e-01,  4.0219e-04]],\n",
       "\n",
       "          [[ 5.0009e-01, -3.1329e-04,  5.0732e-01,  2.0198e-04]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 4.9996e-01,  6.4256e-04,  5.0609e-01, -6.4523e-05]],\n",
       "\n",
       "          [[ 4.9984e-01,  6.6073e-04,  5.0613e-01, -2.9522e-04]],\n",
       "\n",
       "          [[ 4.9972e-01,  6.5843e-04,  5.0620e-01, -5.6868e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0000e-01,  6.4939e-04,  5.0617e-01,  7.0351e-04]],\n",
       "\n",
       "          [[ 5.0002e-01,  6.7039e-04,  5.0617e-01,  4.3410e-04]],\n",
       "\n",
       "          [[ 5.0002e-01,  6.5317e-04,  5.0613e-01,  1.9933e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0000e-01,  4.4503e-04,  5.0634e-01, -7.2432e-05]],\n",
       "\n",
       "          [[ 4.9989e-01,  4.5659e-04,  5.0639e-01, -2.9032e-04]],\n",
       "\n",
       "          [[ 4.9981e-01,  4.5412e-04,  5.0646e-01, -5.5249e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0003e-01,  4.5133e-04,  5.0643e-01,  6.8446e-04]],\n",
       "\n",
       "          [[ 5.0006e-01,  4.7675e-04,  5.0642e-01,  4.3204e-04]],\n",
       "\n",
       "          [[ 5.0004e-01,  4.6832e-04,  5.0638e-01,  1.8588e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 4.9998e-01,  2.7339e-04,  5.0660e-01, -8.6655e-05]],\n",
       "\n",
       "          [[ 4.9988e-01,  2.7222e-04,  5.0663e-01, -3.0542e-04]],\n",
       "\n",
       "          [[ 4.9982e-01,  2.6754e-04,  5.0664e-01, -5.5733e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9999e-01,  2.5344e-04,  5.0669e-01,  6.5124e-04]],\n",
       "\n",
       "          [[ 5.0003e-01,  2.8618e-04,  5.0667e-01,  4.2407e-04]],\n",
       "\n",
       "          [[ 5.0001e-01,  2.9357e-04,  5.0661e-01,  1.8186e-04]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 5.0000e-01,  1.0310e-04,  5.0904e-01, -1.5963e-04]],\n",
       "\n",
       "          [[ 4.9990e-01,  1.0923e-04,  5.0903e-01, -3.9235e-04]],\n",
       "\n",
       "          [[ 4.9989e-01,  1.3420e-04,  5.0905e-01, -6.5511e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0000e-01,  9.1164e-05,  5.0908e-01,  7.3081e-04]],\n",
       "\n",
       "          [[ 5.0005e-01,  1.2627e-04,  5.0903e-01,  4.5943e-04]],\n",
       "\n",
       "          [[ 5.0006e-01,  1.2508e-04,  5.0901e-01,  1.4503e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0014e-01, -1.4212e-04,  5.0928e-01, -1.1897e-04]],\n",
       "\n",
       "          [[ 5.0004e-01, -1.1312e-04,  5.0925e-01, -3.9595e-04]],\n",
       "\n",
       "          [[ 4.9998e-01, -8.9112e-05,  5.0926e-01, -6.8065e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0004e-01, -1.6710e-04,  5.0930e-01,  7.2973e-04]],\n",
       "\n",
       "          [[ 5.0014e-01, -1.3548e-04,  5.0927e-01,  5.0959e-04]],\n",
       "\n",
       "          [[ 5.0018e-01, -1.3002e-04,  5.0928e-01,  2.1181e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0021e-01, -3.7223e-04,  5.0953e-01, -4.8456e-05]],\n",
       "\n",
       "          [[ 5.0007e-01, -3.5347e-04,  5.0952e-01, -3.1740e-04]],\n",
       "\n",
       "          [[ 4.9997e-01, -3.3634e-04,  5.0953e-01, -6.1608e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0007e-01, -3.9066e-04,  5.0953e-01,  6.7801e-04]],\n",
       "\n",
       "          [[ 5.0016e-01, -3.7332e-04,  5.0952e-01,  4.9168e-04]],\n",
       "\n",
       "          [[ 5.0023e-01, -3.6635e-04,  5.0953e-01,  2.4777e-04]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 4.9983e-01,  8.2697e-04,  5.0806e-01, -7.0531e-05]],\n",
       "\n",
       "          [[ 4.9960e-01,  8.4321e-04,  5.0815e-01, -3.6730e-04]],\n",
       "\n",
       "          [[ 4.9953e-01,  8.7521e-04,  5.0824e-01, -6.7594e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9998e-01,  8.4734e-04,  5.0816e-01,  8.1204e-04]],\n",
       "\n",
       "          [[ 5.0001e-01,  8.4572e-04,  5.0814e-01,  5.0098e-04]],\n",
       "\n",
       "          [[ 4.9998e-01,  8.1329e-04,  5.0807e-01,  2.3968e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 4.9989e-01,  5.7450e-04,  5.0835e-01, -6.4008e-05]],\n",
       "\n",
       "          [[ 4.9972e-01,  5.8490e-04,  5.0846e-01, -3.3576e-04]],\n",
       "\n",
       "          [[ 4.9971e-01,  6.1352e-04,  5.0856e-01, -6.3782e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0003e-01,  6.1278e-04,  5.0846e-01,  8.1030e-04]],\n",
       "\n",
       "          [[ 5.0005e-01,  6.2277e-04,  5.0841e-01,  5.0085e-04]],\n",
       "\n",
       "          [[ 5.0002e-01,  5.8288e-04,  5.0834e-01,  2.2560e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 4.9986e-01,  3.6531e-04,  5.0865e-01, -9.5078e-05]],\n",
       "\n",
       "          [[ 4.9971e-01,  3.6404e-04,  5.0869e-01, -3.5542e-04]],\n",
       "\n",
       "          [[ 4.9970e-01,  3.7492e-04,  5.0874e-01, -6.5321e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9995e-01,  3.6155e-04,  5.0877e-01,  7.7093e-04]],\n",
       "\n",
       "          [[ 5.0000e-01,  4.0084e-04,  5.0870e-01,  4.9143e-04]],\n",
       "\n",
       "          [[ 4.9997e-01,  3.8409e-04,  5.0863e-01,  2.0389e-04]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 5.0011e-01, -2.0763e-04,  5.1209e-01, -1.6288e-04]],\n",
       "\n",
       "          [[ 5.0000e-01, -2.0719e-04,  5.1207e-01, -4.1623e-04]],\n",
       "\n",
       "          [[ 5.0000e-01, -1.9285e-04,  5.1207e-01, -7.0668e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0002e-01, -2.5879e-04,  5.1213e-01,  7.5300e-04]],\n",
       "\n",
       "          [[ 5.0016e-01, -2.1377e-04,  5.1201e-01,  4.9875e-04]],\n",
       "\n",
       "          [[ 5.0024e-01, -2.0788e-04,  5.1201e-01,  1.5951e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0030e-01, -4.9478e-04,  5.1234e-01, -1.4190e-04]],\n",
       "\n",
       "          [[ 5.0015e-01, -4.8737e-04,  5.1228e-01, -4.3224e-04]],\n",
       "\n",
       "          [[ 5.0003e-01, -4.8646e-04,  5.1228e-01, -7.1436e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9994e-01, -5.8392e-04,  5.1243e-01,  7.4905e-04]],\n",
       "\n",
       "          [[ 5.0017e-01, -5.3835e-04,  5.1231e-01,  5.5431e-04]],\n",
       "\n",
       "          [[ 5.0030e-01, -5.2253e-04,  5.1232e-01,  2.2819e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0040e-01, -7.7436e-04,  5.1258e-01, -3.0481e-05]],\n",
       "\n",
       "          [[ 5.0019e-01, -7.6652e-04,  5.1253e-01, -3.2452e-04]],\n",
       "\n",
       "          [[ 5.0005e-01, -7.8492e-04,  5.1251e-01, -6.2014e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9996e-01, -8.5392e-04,  5.1266e-01,  7.0004e-04]],\n",
       "\n",
       "          [[ 5.0021e-01, -8.2395e-04,  5.1259e-01,  5.3732e-04]],\n",
       "\n",
       "          [[ 5.0036e-01, -8.0850e-04,  5.1259e-01,  2.6748e-04]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 4.9999e-01,  6.8589e-04,  5.1094e-01, -3.4146e-05]],\n",
       "\n",
       "          [[ 4.9981e-01,  7.1819e-04,  5.1102e-01, -3.6923e-04]],\n",
       "\n",
       "          [[ 4.9981e-01,  7.3146e-04,  5.1113e-01, -7.3777e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0009e-01,  6.5342e-04,  5.1112e-01,  8.9639e-04]],\n",
       "\n",
       "          [[ 5.0012e-01,  6.7081e-04,  5.1101e-01,  5.3921e-04]],\n",
       "\n",
       "          [[ 5.0005e-01,  6.3422e-04,  5.1097e-01,  2.4591e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 5.0005e-01,  3.7357e-04,  5.1125e-01, -4.4244e-05]],\n",
       "\n",
       "          [[ 4.9995e-01,  3.9451e-04,  5.1137e-01, -3.3323e-04]],\n",
       "\n",
       "          [[ 5.0002e-01,  4.0770e-04,  5.1149e-01, -6.6883e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0018e-01,  3.6779e-04,  5.1141e-01,  8.6029e-04]],\n",
       "\n",
       "          [[ 5.0016e-01,  3.9379e-04,  5.1128e-01,  5.2522e-04]],\n",
       "\n",
       "          [[ 5.0010e-01,  3.5462e-04,  5.1123e-01,  2.1328e-04]]],\n",
       "\n",
       "\n",
       "         [[[ 4.9993e-01,  1.1439e-04,  5.1165e-01, -8.6109e-05]],\n",
       "\n",
       "          [[ 4.9983e-01,  1.2019e-04,  5.1169e-01, -3.5899e-04]],\n",
       "\n",
       "          [[ 4.9988e-01,  1.2295e-04,  5.1172e-01, -6.8572e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 5.0003e-01,  4.8980e-05,  5.1177e-01,  7.9688e-04]],\n",
       "\n",
       "          [[ 5.0011e-01,  1.0401e-04,  5.1164e-01,  4.9956e-04]],\n",
       "\n",
       "          [[ 5.0008e-01,  9.5486e-05,  5.1160e-01,  1.8536e-04]]]],\n",
       "\n",
       "\n",
       "\n",
       "        ...,\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 4.7746e-01,  7.3609e-02,  4.6918e-01, -7.3572e-03]],\n",
       "\n",
       "          [[ 4.9873e-01,  7.4300e-02,  4.6823e-01,  9.2374e-05]],\n",
       "\n",
       "          [[ 5.0105e-01,  7.4376e-02,  4.6669e-01,  2.8824e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.6657e-01,  7.2554e-02,  4.6957e-01, -2.0294e-02]],\n",
       "\n",
       "          [[ 4.8939e-01,  7.2969e-02,  4.7040e-01, -1.5258e-02]],\n",
       "\n",
       "          [[ 4.8544e-01,  7.3068e-02,  4.6868e-01, -1.1464e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.8384e-01,  7.5667e-02,  4.6563e-01, -7.0435e-03]],\n",
       "\n",
       "          [[ 5.0539e-01,  7.6204e-02,  4.6573e-01, -4.6233e-04]],\n",
       "\n",
       "          [[ 4.9866e-01,  7.6564e-02,  4.6488e-01,  1.8822e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.6443e-01,  7.4235e-02,  4.6537e-01, -1.8478e-02]],\n",
       "\n",
       "          [[ 4.8456e-01,  7.5047e-02,  4.6600e-01, -1.4044e-02]],\n",
       "\n",
       "          [[ 4.8153e-01,  7.5147e-02,  4.6523e-01, -1.1305e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.8571e-01,  7.8113e-02,  4.6443e-01, -6.3954e-03]],\n",
       "\n",
       "          [[ 5.0184e-01,  7.8723e-02,  4.6407e-01,  6.2333e-04]],\n",
       "\n",
       "          [[ 4.8201e-01,  7.8435e-02,  4.6327e-01,  1.9653e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.8381e-01,  7.6179e-02,  4.6033e-01, -1.7127e-02]],\n",
       "\n",
       "          [[ 4.9146e-01,  7.7368e-02,  4.6217e-01, -1.2801e-02]],\n",
       "\n",
       "          [[ 4.8145e-01,  7.7398e-02,  4.6339e-01, -9.8925e-03]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 4.7626e-01,  6.7443e-02,  4.8288e-01, -9.3586e-03]],\n",
       "\n",
       "          [[ 4.7963e-01,  6.7862e-02,  4.8205e-01, -4.3943e-04]],\n",
       "\n",
       "          [[ 4.8446e-01,  6.6246e-02,  4.7913e-01,  3.6830e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.5741e-01,  6.4187e-02,  4.8294e-01, -1.8000e-02]],\n",
       "\n",
       "          [[ 4.9020e-01,  6.5024e-02,  4.8295e-01, -1.4270e-02]],\n",
       "\n",
       "          [[ 4.9321e-01,  6.5978e-02,  4.8251e-01, -1.2177e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.7150e-01,  7.0882e-02,  4.7788e-01, -8.7293e-03]],\n",
       "\n",
       "          [[ 4.7574e-01,  7.1143e-02,  4.7570e-01, -5.1112e-04]],\n",
       "\n",
       "          [[ 4.7773e-01,  7.0078e-02,  4.7326e-01,  3.4576e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9083e-01,  6.7021e-02,  4.7847e-01, -2.0726e-02]],\n",
       "\n",
       "          [[ 5.0182e-01,  6.7755e-02,  4.7915e-01, -1.5676e-02]],\n",
       "\n",
       "          [[ 4.8458e-01,  6.9302e-02,  4.7764e-01, -1.1551e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.7259e-01,  7.1766e-02,  4.7278e-01, -8.3312e-03]],\n",
       "\n",
       "          [[ 4.8556e-01,  7.2241e-02,  4.7087e-01, -1.5042e-03]],\n",
       "\n",
       "          [[ 4.8922e-01,  7.1576e-02,  4.6834e-01,  1.6392e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9278e-01,  6.9342e-02,  4.7391e-01, -2.0657e-02]],\n",
       "\n",
       "          [[ 5.0556e-01,  6.9975e-02,  4.7449e-01, -1.4941e-02]],\n",
       "\n",
       "          [[ 4.8836e-01,  7.0925e-02,  4.7255e-01, -1.1243e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 4.7716e-01,  7.5880e-02,  4.5881e-01, -7.3853e-03]],\n",
       "\n",
       "          [[ 4.9835e-01,  7.6533e-02,  4.5791e-01, -1.7882e-04]],\n",
       "\n",
       "          [[ 5.0090e-01,  7.6638e-02,  4.5649e-01,  2.3857e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.6720e-01,  7.4830e-02,  4.5913e-01, -1.9682e-02]],\n",
       "\n",
       "          [[ 4.8965e-01,  7.5210e-02,  4.6002e-01, -1.4833e-02]],\n",
       "\n",
       "          [[ 4.8527e-01,  7.5320e-02,  4.5832e-01, -1.1267e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.8383e-01,  7.7807e-02,  4.5552e-01, -7.0646e-03]],\n",
       "\n",
       "          [[ 5.0505e-01,  7.8333e-02,  4.5568e-01, -7.0447e-04]],\n",
       "\n",
       "          [[ 4.9834e-01,  7.8716e-02,  4.5491e-01,  1.3959e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.6561e-01,  7.6384e-02,  4.5511e-01, -1.7928e-02]],\n",
       "\n",
       "          [[ 4.8496e-01,  7.7159e-02,  4.5584e-01, -1.3689e-02]],\n",
       "\n",
       "          [[ 4.8144e-01,  7.7255e-02,  4.5510e-01, -1.1136e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.8585e-01,  8.0129e-02,  4.5446e-01, -6.4140e-03]],\n",
       "\n",
       "          [[ 5.0165e-01,  8.0722e-02,  4.5418e-01,  3.9102e-04]],\n",
       "\n",
       "          [[ 4.8162e-01,  8.0449e-02,  4.5352e-01,  1.4844e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.8471e-01,  7.8229e-02,  4.5030e-01, -1.6541e-02]],\n",
       "\n",
       "          [[ 4.9163e-01,  7.9392e-02,  4.5221e-01, -1.2403e-02]],\n",
       "\n",
       "          [[ 4.8122e-01,  7.9416e-02,  4.5340e-01, -9.7314e-03]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 4.7577e-01,  7.0148e-02,  4.7184e-01, -9.3626e-03]],\n",
       "\n",
       "          [[ 4.7917e-01,  7.0560e-02,  4.7106e-01, -6.6700e-04]],\n",
       "\n",
       "          [[ 4.8428e-01,  6.8939e-02,  4.6814e-01,  3.2809e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.5835e-01,  6.6902e-02,  4.7196e-01, -1.7334e-02]],\n",
       "\n",
       "          [[ 4.9041e-01,  6.7734e-02,  4.7200e-01, -1.3810e-02]],\n",
       "\n",
       "          [[ 4.9267e-01,  6.8684e-02,  4.7149e-01, -1.1963e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.7075e-01,  7.3457e-02,  4.6701e-01, -8.7599e-03]],\n",
       "\n",
       "          [[ 4.7509e-01,  7.3683e-02,  4.6489e-01, -7.6364e-04]],\n",
       "\n",
       "          [[ 4.7736e-01,  7.2620e-02,  4.6251e-01,  3.0056e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9152e-01,  6.9591e-02,  4.6768e-01, -2.0136e-02]],\n",
       "\n",
       "          [[ 5.0192e-01,  7.0312e-02,  4.6837e-01, -1.5285e-02]],\n",
       "\n",
       "          [[ 4.8390e-01,  7.1860e-02,  4.6679e-01, -1.1375e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.7208e-01,  7.4184e-02,  4.6212e-01, -8.3198e-03]],\n",
       "\n",
       "          [[ 4.8509e-01,  7.4612e-02,  4.6028e-01, -1.7275e-03]],\n",
       "\n",
       "          [[ 4.8899e-01,  7.3964e-02,  4.5786e-01,  1.1937e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9344e-01,  7.1769e-02,  4.6331e-01, -2.0035e-02]],\n",
       "\n",
       "          [[ 5.0577e-01,  7.2368e-02,  4.6390e-01, -1.4497e-02]],\n",
       "\n",
       "          [[ 4.8792e-01,  7.3322e-02,  4.6190e-01, -1.0988e-02]]]],\n",
       "\n",
       "\n",
       "\n",
       "        [[[[ 4.7687e-01,  7.9582e-02,  4.4857e-01, -7.3579e-03]],\n",
       "\n",
       "          [[ 4.9786e-01,  8.0242e-02,  4.4777e-01, -3.5548e-04]],\n",
       "\n",
       "          [[ 4.9980e-01,  8.0366e-02,  4.4646e-01,  2.0714e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.6797e-01,  7.8519e-02,  4.4893e-01, -1.9045e-02]],\n",
       "\n",
       "          [[ 4.8990e-01,  7.8885e-02,  4.4974e-01, -1.4393e-02]],\n",
       "\n",
       "          [[ 4.8532e-01,  7.9009e-02,  4.4813e-01, -1.1048e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.8332e-01,  8.1386e-02,  4.4546e-01, -7.0390e-03]],\n",
       "\n",
       "          [[ 5.0440e-01,  8.1907e-02,  4.4571e-01, -8.8347e-04]],\n",
       "\n",
       "          [[ 4.9733e-01,  8.2292e-02,  4.4498e-01,  1.0539e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.6606e-01,  7.9909e-02,  4.4512e-01, -1.7349e-02]],\n",
       "\n",
       "          [[ 4.8518e-01,  8.0691e-02,  4.4575e-01, -1.3306e-02]],\n",
       "\n",
       "          [[ 4.8132e-01,  8.0823e-02,  4.4505e-01, -1.0920e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.8552e-01,  8.3560e-02,  4.4460e-01, -6.4481e-03]],\n",
       "\n",
       "          [[ 5.0111e-01,  8.4161e-02,  4.4442e-01,  1.7619e-04]],\n",
       "\n",
       "          [[ 4.8063e-01,  8.3891e-02,  4.4376e-01,  1.1143e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.8527e-01,  8.1593e-02,  4.4053e-01, -1.6010e-02]],\n",
       "\n",
       "          [[ 4.9214e-01,  8.2765e-02,  4.4233e-01, -1.2078e-02]],\n",
       "\n",
       "          [[ 4.8137e-01,  8.2830e-02,  4.4349e-01, -9.5697e-03]]],\n",
       "\n",
       "\n",
       "         ...,\n",
       "\n",
       "\n",
       "         [[[ 4.7539e-01,  7.4333e-02,  4.6115e-01, -9.2731e-03]],\n",
       "\n",
       "          [[ 4.7822e-01,  7.4742e-02,  4.6047e-01, -7.2216e-04]],\n",
       "\n",
       "          [[ 4.8252e-01,  7.3118e-02,  4.5753e-01,  3.0403e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.5912e-01,  7.1068e-02,  4.6126e-01, -1.6740e-02]],\n",
       "\n",
       "          [[ 4.9080e-01,  7.1904e-02,  4.6130e-01, -1.3361e-02]],\n",
       "\n",
       "          [[ 4.9272e-01,  7.2863e-02,  4.6078e-01, -1.1720e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.7038e-01,  7.7483e-02,  4.5646e-01, -8.7109e-03]],\n",
       "\n",
       "          [[ 4.7413e-01,  7.7708e-02,  4.5447e-01, -8.7597e-04]],\n",
       "\n",
       "          [[ 4.7568e-01,  7.6644e-02,  4.5214e-01,  2.7403e-03]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9238e-01,  7.3614e-02,  4.5712e-01, -1.9491e-02]],\n",
       "\n",
       "          [[ 5.0236e-01,  7.4338e-02,  4.5780e-01, -1.4819e-02]],\n",
       "\n",
       "          [[ 4.8398e-01,  7.5880e-02,  4.5625e-01, -1.1156e-02]]],\n",
       "\n",
       "\n",
       "         [[[ 4.7191e-01,  7.8062e-02,  4.5177e-01, -8.2631e-03]],\n",
       "\n",
       "          [[ 4.8441e-01,  7.8484e-02,  4.5007e-01, -1.8841e-03]],\n",
       "\n",
       "          [[ 4.8775e-01,  7.7837e-02,  4.4774e-01,  9.0328e-04]],\n",
       "\n",
       "          ...,\n",
       "\n",
       "          [[ 4.9420e-01,  7.5643e-02,  4.5293e-01, -1.9422e-02]],\n",
       "\n",
       "          [[ 5.0624e-01,  7.6244e-02,  4.5349e-01, -1.4080e-02]],\n",
       "\n",
       "          [[ 4.8814e-01,  7.7190e-02,  4.5157e-01, -1.0777e-02]]]]],\n",
       "       device='cuda:0')"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# y_pred[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<video src=\"./figures//acoustic_scattering_inclusions/rollout_video/epochac_inclusion_example_acoustic_scattering_inclusions.mp4\" controls  width=\"640\"  height=\"360\">\n",
       "      Your browser does not support the <code>video</code> element.\n",
       "    </video>"
      ],
      "text/plain": [
       "<IPython.core.display.Video object>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from IPython.display import Video\n",
    "\n",
    "Video(f'{output_dir}/{metadata.dataset_name}/rollout_video/epochac_shear_{metadata.dataset_name}.mp4', width=640, height=360) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Awesome! We've made predictions with our pretrained model. Now let's look into what would happen if we needed to use the model for a downstream task and didn't want to go through the effort of first moving the data into the Well format.\n",
    "\n",
    "## Part 2: Non-Well data\n",
    "\n",
    "Now lets see what we'd do in the case where we don't have Well structured data. The key difference here is that we'd need to define our own data transformation objects to make sure that every object in the pipeline is getting the data in the format they need it.\n",
    "\n",
    "We also need to make sure that our field_to_index_map is lined up with the new data which may include fields we haven't seen before.\n",
    "\n",
    "First let's get some extra imports from the library out of the way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from walrus.utils.experiment_utils import align_checkpoint_with_field_to_index_map\n",
    "from the_well.data.datasets import WellMetadata"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's make a hypothetical dataset. This dataset has 4 fields - velocity_x, velocity_y, density, and a new, never-before-seen field \"blubber\". First, we'll check out the existing `field_to_index_map` to see what we can use:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'closed_boundary': 0, 'open_boundary': 1, 'bias_correction': 2, 'pressure': 3, 'velocity_x': 4, 'velocity_y': 5, 'velocity_z': 6, 'zeros_like_density': 7, 'speed_of_sound': 8, 'concentration': 9, 'D_xx': 10, 'D_xy': 11, 'D_xz': 12, 'D_yx': 13, 'D_yy': 14, 'D_yz': 15, 'D_zx': 16, 'D_zy': 17, 'D_zz': 18, 'E_xx': 19, 'E_xy': 20, 'E_xz': 21, 'E_yx': 22, 'E_yy': 23, 'E_yz': 24, 'E_zx': 25, 'E_zy': 26, 'E_zz': 27, 'density': 28, 'energy': 29, 'velocity_r': 30, 'velocity_theta': 31, 'velocity_phi': 32, 'momentum_x': 33, 'momentum_y': 34, 'momentum_z': 35, 'pressure_re': 36, 'pressure_im': 37, 'mask': 38, 'magnetic_field_x': 39, 'magnetic_field_y': 40, 'magnetic_field_z': 41, 'A': 42, 'B': 43, 'height': 44, 'internal_energy': 45, 'temperature': 46, 'electron_fraction': 47, 'entropy': 48, 'magnetic_field_log_r': 49, 'magnetic_field_theta': 50, 'magnetic_field_phi': 51, 'velocity_log_r': 52, 'buoyancy': 53, 'tracer': 54, 'log10_density': 55, 'log10_temperature': 56, 'c_zz': 57, 'C_xx': 58, 'C_xy': 59, 'C_xz': 60, 'C_yx': 61, 'C_yy': 62, 'C_yz': 63, 'C_zx': 64, 'C_zy': 65, 'C_zz': 66}"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "field_to_index_map"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three of our fields are covered. Additionally, since Walrus is expecting dimensionally padded data, we'll also need to include a velocity_x which we can concatenate to the end since these are treated as sets and the order doesn't matter.\n",
    "\n",
    "So we'll be passing fields {\"velocity_x\": 4, \"velocity_y\":5, \"velocity_z\": 6, \"density\": 28, \"blubber\": ?????} in the order [4, 5, 28, ????. 6]. \n",
    "\n",
    "The question we need to answer is: how do we deal with blubber? This is fortunately easy enough, we just need to add an extra field to this mapping dictionary and pass it appropriately."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_field_to_index_map = copy.deepcopy(field_to_index_map)\n",
    "new_field_to_index_map[\"blubber\"] = max(field_to_index_map.values()) + 1  # New index for \"blubber\"\n",
    "\n",
    "model = instantiate(\n",
    "    config.model,\n",
    "    n_states=max(new_field_to_index_map.values()) + 1,\n",
    ")\n",
    "\n",
    "\n",
    "# Use the Walrus utility to align the checkpoint\n",
    "revised_model_checkpoint = align_checkpoint_with_field_to_index_map(\n",
    "    checkpoint_state_dict=checkpoint,\n",
    "    model_state_dict=model.state_dict(),\n",
    "    checkpoint_field_to_index_map=field_to_index_map,\n",
    "    model_field_to_index_map=new_field_to_index_map,\n",
    ")\n",
    "\n",
    "# Now load the aligned weights\n",
    "model.load_state_dict(revised_model_checkpoint)\n",
    "\n",
    "model.to(device)\n",
    "model.eval()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we just need to pass data with the right signature. From before, we know the model is using the following fields:\n",
    "- `input_fields` - float tensor [B x T_in x H x W x D x C_var]\n",
    "- `output_fields` - float tensor [B x T_out x H x W x D x C_var]\n",
    "- `constant_fields` - Optional, float tensor[B x H x W x D x C_con]\n",
    "- `boundary_conditions` - int tensor [Bx3x2] \n",
    "- `padded_field_mask` - bool tensor [C_var] \n",
    "- `field_indices` - Int tensor [C_var + C_con] \n",
    "- `metadata` - WellMetadata - Not strictly necessary, but our functions above use this to help with logging, so we'll make one here too"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B = 1\n",
    "T_in = 6\n",
    "T_out = 10\n",
    "H = 128\n",
    "W = 128\n",
    "D = 1\n",
    "C_var = 5  # velocity_x, velocity_y, velocity_z, density, blubber\n",
    "C_con = 0  # No constant fields in this example\n",
    "\n",
    "\n",
    "synthetic_trajectory_example = {\n",
    "    \"input_fields\": torch.randn(B, T_in, H, W, D, C_var, device=device),\n",
    "    \"output_fields\": torch.randn(B, T_out, H, W, D, C_var, device=device),\n",
    "    \"constant_fields\": torch.randn(B, H, W, D, C_con, device=device),\n",
    "    \"boundary_conditions\": torch.tensor([[[2, 2], [2, 2], [2, 2]] for _ in range(B)], device=device),  # Example BCs\n",
    "    \"padded_field_mask\": torch.tensor([True, True, True, True, False], device=device),  # Last field index is padded\n",
    "    \"field_indices\": torch.tensor([4, 5, 28, 67, 6], device=device),  # Indices for all fields\n",
    "    \"metadata\": WellMetadata(\n",
    "        dataset_name=\"synthetic_dataset\",\n",
    "        n_spatial_dims=3,\n",
    "        field_names={0: ['pressure', \"blubber\"], 1: ['velocity_x', 'velocity_y', 'velocity_z'], 2: []},\n",
    "        spatial_resolution=(128, 128, 1),\n",
    "        scalar_names=[], \n",
    "        constant_field_names={0: [], 1: [], 2: []},\n",
    "        constant_scalar_names=[],\n",
    "        boundary_condition_types=[], # Doesn't matter\n",
    "        n_files =[], # Doesn't matter\n",
    "        n_trajectories_per_file=[], # Doesn't matter\n",
    "        n_steps_per_trajectory=[], # Doesn't matter\n",
    "    ),\n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    synthetic_trajectory_example[\"padded_field_mask\"] = synthetic_trajectory_example[\"padded_field_mask\"].to(device) # We're going to want this out here too\n",
    "    inputs, y_ref = formatter.process_input(\n",
    "        synthetic_trajectory_example,\n",
    "        causal_in_time=model.causal_in_time,\n",
    "        predict_delta=True,\n",
    "        train=False,\n",
    "    )\n",
    "    fake_metadata = synthetic_trajectory_example[\"metadata\"]\n",
    "    y_pred, y_ref = rollout_model(\n",
    "        model,\n",
    "        revin,\n",
    "        synthetic_trajectory_example,\n",
    "        formatter,\n",
    "        max_rollout_steps=200,\n",
    "        device=device,\n",
    "    )\n",
    "\n",
    "    # Lets get some extra info so we can visualize our data effectively\n",
    "    # Remove unused fields\n",
    "    y_pred, y_ref = (\n",
    "        y_pred[..., synthetic_trajectory_example[\"padded_field_mask\"]],\n",
    "        y_ref[..., synthetic_trajectory_example[\"padded_field_mask\"]],\n",
    "    )\n",
    "    # Collecting names to make detailed output logs\n",
    "    field_names = flatten_field_names(fake_metadata, include_constants=False)\n",
    "    used_field_names = [\n",
    "        f\n",
    "        for i, f in enumerate(field_names)\n",
    "        if synthetic_trajectory_example[\"padded_field_mask\"][i]\n",
    "    ]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you've used Walrus with both data in the Well format and independent data. Generally when using our training code, it's going to be much easier to use Well formatted data as it handles most of what we've just done automatically for Well formatted data. If you need some guidance on how to do that, we have an example in a second notebook. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "P",
   "language": "python",
   "name": "interp"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
